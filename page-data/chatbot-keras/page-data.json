{"componentChunkName":"component---src-templates-note-js","path":"/chatbot-keras","result":{"data":{"remark":{"fields":{"path":"chatbot-keras"},"meta":{"title":""},"headings":[{"value":"Keras train chatbot"}],"html":"<h1>Keras train chatbot</h1>\n<p><a href=\"https://towardsdatascience.com/how-to-build-your-own-chatbot-using-deep-learning-bb41f970e281\">Original</a> posts describes spet by step what needs to be done to train a chat bot, and what is cools its language independend and all you need is good enough dataset.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt</span> <span class=\"token function\">install</span> python3-pip\npip <span class=\"token function\">install</span> tensorflow nltk numpy scikit_learn</code></pre></div>\n<p>Here is combinedd train script:</p>\n<p><div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> json\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow <span class=\"token keyword\">import</span> keras\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dense<span class=\"token punctuation\">,</span> Embedding<span class=\"token punctuation\">,</span> GlobalAveragePooling1D\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> Tokenizer\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>sequence <span class=\"token keyword\">import</span> pad_sequences\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n\n<span class=\"token comment\"># load intents</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'intents.json'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span>\n    data <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># fill variables from json</span>\n<span class=\"token comment\"># training inputs</span>\ntraining_sentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># training labels</span>\ntraining_labels <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\nlabels <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># training responses</span>\nresponses <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">for</span> intent <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'intents'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> pattern <span class=\"token keyword\">in</span> intent<span class=\"token punctuation\">[</span><span class=\"token string\">'patterns'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        training_sentences<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>pattern<span class=\"token punctuation\">)</span>\n        training_labels<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>intent<span class=\"token punctuation\">[</span><span class=\"token string\">'tag'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    responses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>intent<span class=\"token punctuation\">[</span><span class=\"token string\">'responses'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> intent<span class=\"token punctuation\">[</span><span class=\"token string\">'tag'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> labels<span class=\"token punctuation\">:</span>\n        labels<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>intent<span class=\"token punctuation\">[</span><span class=\"token string\">'tag'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nnum_classes <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># use LabelEncoder from scikit-learn to convert human readable labels into machine understandable</span>\nlbl_encoder <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlbl_encoder<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>training_labels<span class=\"token punctuation\">)</span>\ntraining_labels <span class=\"token operator\">=</span> lbl_encoder<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>training_labels<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># \"vectorize\" sentences</span>\nvocab_size <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\nembedding_dim <span class=\"token operator\">=</span> <span class=\"token number\">16</span>\nmax_len <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\noov_token <span class=\"token operator\">=</span> <span class=\"token string\">\"&lt;OOV>\"</span>\n\ntokenizer <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">(</span>num_words<span class=\"token operator\">=</span>vocab_size<span class=\"token punctuation\">,</span> oov_token<span class=\"token operator\">=</span>oov_token<span class=\"token punctuation\">)</span> <span class=\"token comment\"># adding out of vocabulary token</span>\ntokenizer<span class=\"token punctuation\">.</span>fit_on_texts<span class=\"token punctuation\">(</span>training_sentences<span class=\"token punctuation\">)</span>\nword_index <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>word_index\nsequences <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span>training_sentences<span class=\"token punctuation\">)</span>\npadded_sequences <span class=\"token operator\">=</span> pad_sequences<span class=\"token punctuation\">(</span>sequences<span class=\"token punctuation\">,</span> truncating<span class=\"token operator\">=</span><span class=\"token string\">'post'</span><span class=\"token punctuation\">,</span> maxlen<span class=\"token operator\">=</span>max_len<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># define model</span>\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Embedding<span class=\"token punctuation\">(</span>vocab_size<span class=\"token punctuation\">,</span> embedding_dim<span class=\"token punctuation\">,</span> input_length<span class=\"token operator\">=</span>max_len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>GlobalAveragePooling1D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span>num_classes<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span> optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># print</span>\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># train</span>\nepochs <span class=\"token operator\">=</span> <span class=\"token number\">550</span>\nhistory <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>padded_sequences<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>training_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span>epochs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># saving model</span>\nmodel<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"chat_model\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">import</span> pickle\n\n<span class=\"token comment\"># saving tokenizer</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'tokenizer.pickle'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'wb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> handle<span class=\"token punctuation\">:</span>\n    pickle<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">,</span> handle<span class=\"token punctuation\">,</span> protocol<span class=\"token operator\">=</span>pickle<span class=\"token punctuation\">.</span>HIGHEST_PROTOCOL<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># saving label encoder</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'label_encoder.pickle'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'wb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> ecn_file<span class=\"token punctuation\">:</span>\n    pickle<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>lbl_encoder<span class=\"token punctuation\">,</span> ecn_file<span class=\"token punctuation\">,</span> protocol<span class=\"token operator\">=</span>pickle<span class=\"token punctuation\">.</span>HIGHEST_PROTOCOL<span class=\"token punctuation\">)</span></code></pre></div></p>\n<p>And demo script:</p>\n<p><code class=\"language-text\">embde:chat.py</code></p>\n<p>Bot can answer on few simple phrases from</p>\n<p><div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"intents\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span> <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"greeting\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Hi\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hey\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Is anyone there?\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hello\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hay\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Hello\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hi\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Hi there\"</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"goodbye\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Bye\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"See you later\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Goodbye\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"See you later\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Have a nice day\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Bye! Come back again\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"thanks\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Thanks\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Thank you\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"That's helpful\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Thanks for the help\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Happy to help!\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Any time!\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"My pleasure\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"You're most welcome!\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"about\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Who are you?\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"What are you?\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Who you are?\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"I.m Joana, your bot assistant\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"I'm Joana, an Artificial Intelligent bot\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"name\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"what is your name\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"what should I call you\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"whats your name?\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"You can call me Joana.\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"I'm Joana!\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Just call me as Joana\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"help\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"Could you help me?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"give me a hand please\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Can you help?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"What can you do for me?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"I need a support\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"I need a help\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"support me please\"</span>\n      <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Tell me how can assist you\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Tell me your problem to assist you\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Yes Sure, How can I support you\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"createaccount\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"I need to create a new account\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how to open a new account\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"I want to create an account\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"can you create an account for me\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"how to open a new account\"</span>\n      <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"You can just easily create a new account from our web site\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Just go to our web site and follow the guidelines to create a new account\"</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tag\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"complaint\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"have a complaint\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"I want to raise a complaint\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"there is a complaint about a service\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"responses\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token string\">\"Please provide us your complaint in order to assist you\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div></p>\n<p>Unfortunatelly there is no way to use it in Slack, original idea was to answer on behalf of me to some messages</p>\n<p>But still after short Googling it seems that there are some datasets available for such projects, like:</p>\n<ul>\n<li><a href=\"https://hackernoon.com/top-15-chatbot-datasets-for-nlp-projects-8k2f3zqc\">Top 15 Chatbot Datasets for NLP Projects</a></li>\n<li><a href=\"https://www.analyticsinsight.net/top-10-chatbot-datasets-assisting-in-ml-and-nlp-projects/\">TOP 10 chatbot datasets assisting in ml and nlp projects</a></li>\n</ul>\n<p>And it is so cool, there is an <a href=\"https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus\">archive of Ubuntu support chats</a> imagining a bot which can answer how to write a bash script :)</p>\n<p>Or <a href=\"https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\">this one</a> with phrases from movies</p>"}},"pageContext":{"id":"219fb276-2fbc-5ae5-b580-dcaf42e9f56e"}},"staticQueryHashes":[]}