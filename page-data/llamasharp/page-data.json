{"componentChunkName":"component---src-templates-note-js","path":"/llamasharp/","result":{"data":{"remark":{"fields":{"path":"llamasharp"},"meta":{"title":""},"headings":[{"value":"LLamaSharp"}],"html":"<h1>LLamaSharp</h1>\n<p>In addition to <a href=\"https://mac-blog.org.ua/qwen/\">previous article where i was trying to fine tune model</a> here is one more note</p>\n<p>We have figured out how to fine tune models and more importantly faced the pipeline of model conversion between different formats</p>\n<p>So i was wondering if it will be possible to run model from withing C# without relying on 3rd party server running (aka not ollama, no mlx, etc)</p>\n<p>And it is possible, there is <a href=\"https://github.com/SciSharp/LLamaSharp\">LLamaSharp</a> that can run GGUF models</p>\n<p>And we did prepare GGUF model so, technically we are ready to go, and indeed it is quite simple and literally works out of the box, aka:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">dotnet new console\ndotnet <span class=\"token function\">add</span> package LLamaSharp\ndotnet <span class=\"token function\">add</span> package LLamaSharp.Backend.Cpu</code></pre></div>\n<p>and our Program.cs</p>\n<p><div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token keyword\">using</span> <span class=\"token namespace\">LLama</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token namespace\">LLama<span class=\"token punctuation\">.</span>Common</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token namespace\">LLama<span class=\"token punctuation\">.</span>Native</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token namespace\">LLama<span class=\"token punctuation\">.</span>Sampling</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token namespace\">Microsoft<span class=\"token punctuation\">.</span>Extensions<span class=\"token punctuation\">.</span>Logging<span class=\"token punctuation\">.</span>Abstractions</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// dotnet add package LLamaSharp</span>\n<span class=\"token comment\">// dotnet add package LLamaSharp.Backend.Cpu</span>\n\n<span class=\"token comment\">// Tick to disable stderr logging from LlamaSharp</span>\nNativeLibraryConfig<span class=\"token punctuation\">.</span>All<span class=\"token punctuation\">.</span><span class=\"token function\">WithLogCallback</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>level<span class=\"token punctuation\">,</span> message<span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token class-name\"><span class=\"token keyword\">var</span></span> modelPath <span class=\"token operator\">=</span> <span class=\"token string\">\"/Users/mac/Desktop/finetun/model.gguf\"</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// For Apple Silicon (M1/M2/M3/M4):</span>\n<span class=\"token comment\">// - GpuLayerCount = -1 means offload ALL layers to GPU (Metal), 0 - means CPU only</span>\n<span class=\"token comment\">// - ContextSize = context window (2048 is safe, model supports up to 32768)</span>\n<span class=\"token comment\">// - FlashAttention = true for faster inference on Metal</span>\n<span class=\"token class-name\"><span class=\"token keyword\">var</span></span> parameters <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token constructor-invocation class-name\">ModelParams</span><span class=\"token punctuation\">(</span>modelPath<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{</span>\n  ContextSize <span class=\"token operator\">=</span> <span class=\"token number\">2048</span><span class=\"token punctuation\">,</span>           <span class=\"token comment\">// Can increase up to 32768 if needed</span>\n  GpuLayerCount <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>           <span class=\"token comment\">// -1 = all layers to GPU (Metal on macOS)</span>\n  FlashAttention <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>        <span class=\"token comment\">// Faster attention on Metal</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">using</span> <span class=\"token class-name\"><span class=\"token keyword\">var</span></span> model <span class=\"token operator\">=</span> LLamaWeights<span class=\"token punctuation\">.</span><span class=\"token function\">LoadFromFile</span><span class=\"token punctuation\">(</span>parameters<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">using</span> <span class=\"token class-name\"><span class=\"token keyword\">var</span></span> context <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span><span class=\"token function\">CreateContext</span><span class=\"token punctuation\">(</span>parameters<span class=\"token punctuation\">,</span> NullLogger<span class=\"token punctuation\">.</span>Instance<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token class-name\"><span class=\"token keyword\">var</span></span> executor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token constructor-invocation class-name\">InteractiveExecutor</span><span class=\"token punctuation\">(</span>context<span class=\"token punctuation\">,</span> NullLogger<span class=\"token punctuation\">.</span>Instance<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token class-name\"><span class=\"token keyword\">var</span></span> input <span class=\"token operator\">=</span> <span class=\"token string\">\"Write a function that calculates the average of two numbers.\"</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token class-name\"><span class=\"token keyword\">var</span></span> inferenceParams <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token constructor-invocation class-name\">InferenceParams</span>\n<span class=\"token punctuation\">{</span>\n  MaxTokens <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span>\n  SamplingPipeline <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token constructor-invocation class-name\">DefaultSamplingPipeline</span>\n  <span class=\"token punctuation\">{</span>\n    Temperature <span class=\"token operator\">=</span> <span class=\"token number\">0.7f</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  AntiPrompts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"&lt;|im_end|>\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"&lt;|endoftext|>\"</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\">// Stop tokens for Qwen</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">await</span> <span class=\"token keyword\">foreach</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\"><span class=\"token keyword\">var</span></span> token <span class=\"token keyword\">in</span> executor<span class=\"token punctuation\">.</span><span class=\"token function\">InferAsync</span><span class=\"token punctuation\">(</span>input<span class=\"token punctuation\">,</span> inferenceParams<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{</span>\n  Console<span class=\"token punctuation\">.</span><span class=\"token function\">Write</span><span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\nConsole<span class=\"token punctuation\">.</span><span class=\"token function\">WriteLine</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div></p>\n<p>so we can <code class=\"language-text\">dotnet run</code> and it will print model output.</p>"}},"pageContext":{"id":"fe2f4b2e-dbcc-5dd8-b510-aca50fc2319c"}},"staticQueryHashes":[],"slicesMap":{}}